import local_config as config
import requests
import datetime
import json
import os
import sys
from tinydb import TinyDB, where
import time
import logging
from logging.handlers import RotatingFileHandler
import pickledb
from zk import ZK, const

EMPLOYEE_NOT_FOUND_ERROR_MESSAGE = "No Employee found for the given employee field value"
EMPLOYEE_INACTIVE_ERROR_MESSAGE = "Transactions cannot be created for an Inactive Employee"
DUPLICATE_EMPLOYEE_CHECKIN_ERROR_MESSAGE = "This employee already has a log with the same timestamp"
allowlisted_errors = [EMPLOYEE_NOT_FOUND_ERROR_MESSAGE, EMPLOYEE_INACTIVE_ERROR_MESSAGE, DUPLICATE_EMPLOYEE_CHECKIN_ERROR_MESSAGE]

if hasattr(config,'allowed_exceptions'):
    allowlisted_errors_temp = []
    for error_number in config.allowed_exceptions:
        allowlisted_errors_temp.append(allowlisted_errors[error_number-1])
    allowlisted_errors = allowlisted_errors_temp

device_punch_values_IN = getattr(config, 'device_punch_values_IN', [0,4])
device_punch_values_OUT = getattr(config, 'device_punch_values_OUT', [1,5])
ERPNEXT_VERSION = getattr(config, 'ERPNEXT_VERSION', 14)

# possible area of further developemt
    # Real-time events - setup getting events pushed from the machine rather then polling.
        #- this is documented as 'Real-time events' in the ZKProtocol manual.

# Notes:
# Status Keys in status.json
#  - lift_off_timestamp
#  - mission_accomplished_timestamp
#  - <device_id>_pull_timestamp
#  - <device_id>_push_timestamp
#  - <shift_type>_sync_timestamp

def main():
    """Takes care of checking if it is time to pull data based on config,
    then calling the relevant functions to pull data and push to ERPNext.
    """
    try:
        # Use search or another method to correctly retrieve the '_default' entry
        default_status = status.search(where('_default') == '_default')
        
        # Ensure default_status is not empty
        if default_status:
            default_status = default_status[0]  # Get the first matching document
            
            lift_off_status = default_status.get('1', None)
            
            # Ensure lift_off_status is not None before accessing its 'lift_off_timestamp'
            if lift_off_status is not None:
                last_lift_off_timestamp = _safe_convert_date(lift_off_status.get('lift_off_timestamp', None), "%Y-%m-%d %H:%M:%S.%f")
            else:
                last_lift_off_timestamp = None
        else:
            last_lift_off_timestamp = None

        # Check if it's time to pull data or if there is no previous timestamp
        if (last_lift_off_timestamp and last_lift_off_timestamp < datetime.datetime.now() - datetime.timedelta(minutes=config.PULL_FREQUENCY)) or not last_lift_off_timestamp:
            status.upsert({'lift_off_timestamp': str(datetime.datetime.now())}, where('lift_off_timestamp') == 'lift_off_timestamp')
            info_logger.info("Cleared for lift off!")
            
            for device in config.devices:
                device_attendance_logs = None
                info_logger.info("Processing Device: "+ device['device_id'])
                
                dump_file = get_dump_file_name_and_directory(device['device_id'], device['ip'])
                if os.path.exists(dump_file):
                    info_logger.error('Device Attendance Dump Found in Log Directory. This can mean the program crashed unexpectedly. Retrying with dumped data.')
                    with open(dump_file, 'r') as f:
                        file_contents = f.read()
                        if file_contents:
                            device_attendance_logs = list(map(lambda x: _apply_function_to_key(x, 'timestamp', datetime.datetime.fromtimestamp), json.loads(file_contents)))
                
                try:
                    pull_process_and_push_data(device, device_attendance_logs)
                    status.upsert({f'{device["device_id"]}_push_timestamp': str(datetime.datetime.now())}, where(f'{device["device_id"]}_push_timestamp') == f'{device["device_id"]}_push_timestamp')
                    if os.path.exists(dump_file):
                        os.remove(dump_file)
                    info_logger.info("Successfully processed Device: "+ device['device_id'])
                except:
                    error_logger.exception('Exception when calling pull_process_and_push_data function for device ' + json.dumps(device, default=str))
            
            if hasattr(config, 'shift_type_device_mapping'):
                update_shift_last_sync_timestamp(config.shift_type_device_mapping)
            
            status.upsert({'mission_accomplished_timestamp': str(datetime.datetime.now())}, where('mission_accomplished_timestamp') == 'mission_accomplished_timestamp')
            info_logger.info("Mission Accomplished!")
    
    except:
        error_logger.exception('Exception has occurred in the main function...')




def pull_process_and_push_data(device, device_attendance_logs=None):
    """ Takes a single device config as param and pulls data from that device.

    params:
    device: a single device config object from the local_config file
    device_attendance_logs: fetching from device is skipped if this param is passed. used to restart failed fetches from previous runs.
    """
    attendance_success_log_file = '_'.join(["attendance_success_log", device['device_id']])
    attendance_failed_log_file = '_'.join(["attendance_failed_log", device['device_id']])
    attendance_success_logger = setup_logger(attendance_success_log_file, '/'.join([config.LOGS_DIRECTORY, attendance_success_log_file])+'.log')
    attendance_failed_logger = setup_logger(attendance_failed_log_file, '/'.join([config.LOGS_DIRECTORY, attendance_failed_log_file])+'.log')
    if not device_attendance_logs:
        device_attendance_logs = get_all_attendance_from_device(device['ip'], device_id=device['device_id'], clear_from_device_on_fetch=device['clear_from_device_on_fetch'])
        if not device_attendance_logs:
            return
    # for finding the last successfull push and restart from that point (or) from a set 'config.IMPORT_START_DATE' (whichever is later)
    index_of_last = -1
    last_line = get_last_line_from_file('/'.join([config.LOGS_DIRECTORY, attendance_success_log_file])+'.log')
    import_start_date = _safe_convert_date(config.IMPORT_START_DATE, "%Y%m%d")
    if last_line or import_start_date:
        last_user_id = None
        last_timestamp = None
        if last_line:
            last_user_id, last_timestamp = last_line.split("\t")[4:6]
            last_timestamp = datetime.datetime.fromtimestamp(float(last_timestamp))
        if import_start_date:
            if last_timestamp:
                if last_timestamp < import_start_date:
                    last_timestamp = import_start_date
                    last_user_id = None
            else:
                last_timestamp = import_start_date
        for i, x in enumerate(device_attendance_logs):
            if last_user_id and last_timestamp:
                if last_user_id == str(x['user_id']) and last_timestamp == x['timestamp']:
                    index_of_last = i
                    break
            elif last_timestamp:
                if x['timestamp'] >= last_timestamp:
                    index_of_last = i
                    break

    for device_attendance_log in device_attendance_logs[index_of_last+1:]:
        punch_direction = device['punch_direction']
        if punch_direction == 'AUTO':
            if device_attendance_log['punch'] in device_punch_values_OUT:
                punch_direction = 'OUT'
            elif device_attendance_log['punch'] in device_punch_values_IN:
                punch_direction = 'IN'
            else:
                punch_direction = None
        erpnext_status_code, erpnext_message = send_to_erpnext(device_attendance_log['user_id'], device_attendance_log['timestamp'], device['device_id'], punch_direction)
        if erpnext_status_code == 200:
            attendance_success_logger.info("\t".join([erpnext_message, str(device_attendance_log['uid']),
                str(device_attendance_log['user_id']), str(device_attendance_log['timestamp'].timestamp()),
                str(device_attendance_log['punch']), str(device_attendance_log['status']),
                json.dumps(device_attendance_log, default=str)]))
        else:
            attendance_failed_logger.error("\t".join([str(erpnext_status_code), str(device_attendance_log['uid']),
                str(device_attendance_log['user_id']), str(device_attendance_log['timestamp'].timestamp()),
                str(device_attendance_log['punch']), str(device_attendance_log['status']),
                json.dumps(device_attendance_log, default=str)]))
            if not(any(error in erpnext_message for error in allowlisted_errors)):
                raise Exception('API Call to ERPNext Failed.')


def get_all_attendance_from_device(ip, port=4370, timeout=30, device_id=None, clear_from_device_on_fetch=False):
    #  Sample Attendance Logs [{'punch': 255, 'user_id': '22', 'uid': 12349, 'status': 1, 'timestamp': datetime.datetime(2019, 2, 26, 20, 31, 29)},{'punch': 255, 'user_id': '7', 'uid': 7, 'status': 1, 'timestamp': datetime.datetime(2019, 2, 26, 20, 31, 36)}]
    zk = ZK(ip, port=port, timeout=timeout)
    conn = None
    attendances = []
    try:
        conn = zk.connect()
        x = conn.disable_device()
        # device is disabled when fetching data
        info_logger.info("\t".join((ip, "Device Disable Attempted. Result:", str(x))))
        attendances = conn.get_attendance()
        info_logger.info("\t".join((ip, "Attendances Fetched:", str(len(attendances)))))
        status.upsert({f'{device_id}_push_timestamp': None}, where(f'{device_id}_push_timestamp') == f'{device_id}_push_timestamp')
        status.upsert({f'{device_id}_pull_timestamp': str(datetime.datetime.now())}, where(f'{device_id}_pull_timestamp') == f'{device_id}_pull_timestamp')
        if len(attendances):
            # keeping a backup before clearing data incase the programs fails.
            # if everything goes well then this file is removed automatically at the end.
            dump_file_name = get_dump_file_name_and_directory(device_id, ip)
            with open(dump_file_name, 'w+') as f:
                f.write(json.dumps(list(map(lambda x: x.__dict__, attendances)), default=datetime.datetime.timestamp))
            if clear_from_device_on_fetch:
                x = conn.clear_attendance()
                info_logger.info("\t".join((ip, "Attendance Clear Attempted. Result:", str(x))))
        x = conn.enable_device()
        info_logger.info("\t".join((ip, "Device Enable Attempted. Result:", str(x))))
    except:
        error_logger.exception(str(ip)+' exception when fetching from device...')
        raise Exception('Device fetch failed.')
    finally:
        if conn:
            conn.disconnect()
    return list(map(lambda x: x.__dict__, attendances))


def send_to_erpnext(employee_field_value, timestamp, device_id=None, log_type=None):
    """
    Example: send_to_erpnext('12349',datetime.datetime.now(),'HO1','IN')
    """
    endpoint_app = "hrms" if ERPNEXT_VERSION > 13 else "erpnext"
    url = f"{config.ERPNEXT_URL}/api/method/{endpoint_app}.hr.doctype.employee_checkin.employee_checkin.add_log_based_on_employee_field"
    headers = {
        'Authorization': "token "+ config.ERPNEXT_API_KEY + ":" + config.ERPNEXT_API_SECRET,
        'Accept': 'application/json'
    }
    data = {
        'employee_field_value' : employee_field_value,
        'timestamp' : timestamp.__str__(),
        'device_id' : device_id,
        'log_type' : log_type
    }
    response = requests.request("POST", url, headers=headers, json=data)
    if response.status_code == 200:
        return 200, json.loads(response._content)['message']['name']
    else:
        error_str = _safe_get_error_str(response)
        if EMPLOYEE_NOT_FOUND_ERROR_MESSAGE in error_str:
            error_logger.error('\t'.join(['Error during ERPNext API Call.', str(employee_field_value), str(timestamp.timestamp()), str(device_id), str(log_type), error_str]))
            # TODO: send email?
        else:
            error_logger.error('\t'.join(['Error during ERPNext API Call.', str(employee_field_value), str(timestamp.timestamp()), str(device_id), str(log_type), error_str]))
        return response.status_code, error_str

def update_shift_last_sync_timestamp(shift_type_device_mapping):
    """
    ### algo for updating the sync_current_timestamp
    - get a list of devices to check
    - check if all the devices have a non 'None' push_timestamp
        - check if the earliest of the pull timestamp is greater than sync_current_timestamp for each shift name
            - then update this min of pull timestamp to the shift

    """
    for shift_type_device_map in shift_type_device_mapping:
        all_devices_pushed = True
        pull_timestamp_array = []
        for device_id in shift_type_device_map['related_device_id']:
            if not status.get(f'{device_id}_push_timestamp'):
                all_devices_pushed = False
                break
            pull_timestamp_array.append(_safe_convert_date(status.get(f'{device_id}_pull_timestamp'), "%Y-%m-%d %H:%M:%S.%f"))
        if all_devices_pushed:
            min_pull_timestamp = min(pull_timestamp_array)
            if isinstance(shift_type_device_map['shift_type_name'], str): # for backward compatibility of config file
                shift_type_device_map['shift_type_name'] = [shift_type_device_map['shift_type_name']]
            for shift in shift_type_device_map['shift_type_name']:
                try:
                    sync_current_timestamp = _safe_convert_date(status.get(f'{shift}_sync_timestamp'), "%Y-%m-%d %H:%M:%S.%f")
                    if (sync_current_timestamp and min_pull_timestamp > sync_current_timestamp) or (min_pull_timestamp and not sync_current_timestamp):
                        response_code = send_shift_sync_to_erpnext(shift, min_pull_timestamp)
                        if response_code == 200:
                            status.set(f'{shift}_sync_timestamp', str(min_pull_timestamp))
                except:
                    error_logger.exception('Exception in update_shift_last_sync_timestamp, for shift:'+shift)

def send_shift_sync_to_erpnext(shift_type_name, sync_timestamp):
    url = config.ERPNEXT_URL + "/api/resource/Shift Type/" + shift_type_name
    headers = {
        'Authorization': "token "+ config.ERPNEXT_API_KEY + ":" + config.ERPNEXT_API_SECRET,
        'Accept': 'application/json'
    }
    data = {
        "last_sync_of_checkin" : str(sync_timestamp)
    }
    try:
        response = requests.request("PUT", url, headers=headers, data=json.dumps(data))
        if response.status_code == 200:
            info_logger.info("\t".join(['Shift Type last_sync_of_checkin Updated', str(shift_type_name), str(sync_timestamp.timestamp())]))
        else:
            error_str = _safe_get_error_str(response)
            error_logger.error('\t'.join(['Error during ERPNext Shift Type API Call.', str(shift_type_name), str(sync_timestamp.timestamp()), error_str]))
        return response.status_code
    except:
        error_logger.exception("\t".join(['exception when updating last_sync_of_checkin in Shift Type', str(shift_type_name), str(sync_timestamp.timestamp())]))

def get_last_line_from_file(file):
    # concerns to address(may be much later):
        # how will last line lookup work with log rotation when a new file is created?
            #- will that new file be empty at any time? or will it have a partial line from the previous file?
    line = None
    if os.stat(file).st_size < 5000:
        # quick hack to handle files with one line
        with open(file, 'r') as f:
            for line in f:
                pass
    else:
        # optimized for large log files
        with open(file, 'rb') as f:
            f.seek(-2, os.SEEK_END)
            while f.read(1) != b'\n':
                f.seek(-2, os.SEEK_CUR)
            line = f.readline().decode()
    return line


def setup_logger(name, log_file, level=logging.INFO, formatter=None):

    if not formatter:
        formatter = logging.Formatter('%(asctime)s\t%(levelname)s\t%(message)s')

    handler = RotatingFileHandler(log_file, maxBytes=10000000, backupCount=50)
    handler.setFormatter(formatter)

    logger = logging.getLogger(name)
    logger.setLevel(level)
    if not logger.hasHandlers():
        logger.addHandler(handler)

    return logger

def get_dump_file_name_and_directory(device_id, device_ip):
    return config.LOGS_DIRECTORY + '/' + device_id + "_" + device_ip.replace('.', '_') + '_last_fetch_dump.json'

def _apply_function_to_key(obj, key, fn):
    obj[key] = fn(obj[key])
    return obj

def _safe_convert_date(datestring, pattern):
    try:
        return datetime.datetime.strptime(datestring, pattern)
    except:
        return None

def _safe_get_error_str(res):
    try:
        error_json = json.loads(res._content)
        if 'exc' in error_json: # this means traceback is available
            error_str = json.loads(error_json['exc'])[0]
        else:
            error_str = json.dumps(error_json)
    except:
        error_str = str(res.__dict__)
    return error_str

# setup logger and status
if not os.path.exists(config.LOGS_DIRECTORY):
    os.makedirs(config.LOGS_DIRECTORY)
error_logger = setup_logger('error_logger', '/'.join([config.LOGS_DIRECTORY, 'error.log']), logging.ERROR)
info_logger = setup_logger('info_logger', '/'.join([config.LOGS_DIRECTORY, 'logs.log']))
status = TinyDB('/'.join([config.LOGS_DIRECTORY, 'status.json']), True)

def infinite_loop(sleep_time=15):
    print("Service Running...")
    while True:
        try:
            main()
            time.sleep(sleep_time)
        except BaseException as e:
            print(e)

if __name__ == "__main__":
    infinite_loop()
---------------------------------------------------------Optimized----------------
import local_config as config
import requests
import datetime
import json
import os
import logging
from logging.handlers import RotatingFileHandler
from zk import ZK

def main():
    """Fetches user_id and timestamp, and processes the attendance logs."""
    try:
        for device in config.devices:
            device_attendance_logs = None
            print("Processing Device: "+ device['device_id'])
            dump_file = get_dump_file_name_and_directory(device['device_id'], device['ip'])
            if os.path.exists(dump_file):
                with open(dump_file, 'r') as f:
                    file_contents = f.read()
                    if file_contents:
                        device_attendance_logs = json.loads(file_contents)
            try:
                pull_process_and_push_data(device, device_attendance_logs)
                if os.path.exists(dump_file):
                    os.remove(dump_file)
                print("Successfully processed Device: "+ device['device_id'])
            except Exception as e:
                print(f"Error processing device {device['device_id']}: {e}")
    except Exception as e:
        print(f"Error in main: {e}")

def pull_process_and_push_data(device, device_attendance_logs=None):
    """Processes device attendance logs."""
    if not device_attendance_logs:
        device_attendance_logs = get_all_attendance_from_device(device['ip'], device['device_id'])
        if not device_attendance_logs:
            return
    
    attendance_logs = []  # Initialize an empty list to collect log entries

    for device_attendance_log in device_attendance_logs:
        # Log the type of the object for debugging
        print(f"Type of device_attendance_log: {type(device_attendance_log)}")
        
        try:
            # Assuming device_attendance_log is an object with attributes (not a dictionary)
            user_id = device_attendance_log.user_id
            timestamp = device_attendance_log.timestamp
        except AttributeError as e:
            print(f"Error accessing attributes for device {device['device_id']}: {e}")
            continue

        # Format the timestamp to "YYYY-MM-DD HH:MM:SS"
        timestamp_str = timestamp.strftime('%Y-%m-%d %H:%M:%S')
        
        log_data = {
            'user_id': user_id,
            'timestamp': timestamp_str  # Save the timestamp in the desired format
        }
        
        attendance_logs.append(log_data)  # Add the log entry to the list

    # Now log the entire list as a JSON array
    info_logger.info(json.dumps(attendance_logs))  # Log the list of log entries


def get_all_attendance_from_device(ip, device_id):
    """Fetches attendance logs from the device."""
    zk = ZK(ip)
    conn = None
    attendances = []
    try:
        conn = zk.connect()
        attendances = conn.get_attendance()
    except Exception as e:
        print(f"Error fetching data from device {ip}: {e}")
    finally:
        if conn:
            conn.disconnect()
    return attendances

def get_dump_file_name_and_directory(device_id, device_ip):
    """Returns the path for the attendance dump file."""
    return os.path.join(config.LOGS_DIRECTORY, f"{device_id}_{device_ip.replace('.', '_')}_last_fetch_dump.json")

import datetime

def setup_logger(name, log_directory, level=logging.INFO):
    """Set up a JSON logger with a date-based log file name."""
    # Get the current date in the format "YYYY-MM-DD"
    current_date = datetime.datetime.now().strftime('%Y-%m-%d')
    log_file = os.path.join(log_directory, f"{current_date}_attendance_log.json")
    
    # Set the formatter to only include the JSON log data
    formatter = logging.Formatter('%(message)s')
    
    handler = RotatingFileHandler(log_file, maxBytes=10000000, backupCount=50)
    handler.setFormatter(formatter)
    
    logger = logging.getLogger(name)
    logger.setLevel(level)
    if not logger.hasHandlers():
        logger.addHandler(handler)
    
    return logger

# Initialize the logger to store JSON logs
if not os.path.exists(config.LOGS_DIRECTORY):
    os.makedirs(config.LOGS_DIRECTORY)

info_logger = setup_logger('info_logger', config.LOGS_DIRECTORY)


if __name__ == "__main__":
    main()

--------------------------My success code---------------
import os
import json
import datetime
import logging
from logging.handlers import RotatingFileHandler
from zk import ZK
import local_config
import requests

def setup_logger(name, log_directory, level=logging.INFO):
    """Set up a JSON logger with a date-based log file name."""
    current_date = datetime.datetime.now().strftime('%d-%m-%Y')
    log_file = os.path.join(local_config.LOGS_DIRECTORY, f"{current_date}_attendance_log.json")

    formatter = logging.Formatter('%(message)s')
    handler = RotatingFileHandler(log_file, maxBytes=10000000, backupCount=50)
    handler.setFormatter(formatter)

    logger = logging.getLogger(name)
    logger.setLevel(level)
    if not logger.hasHandlers():
        logger.addHandler(handler)

    return logger

if not os.path.exists(local_config.LOGS_DIRECTORY):
    os.makedirs(local_config.LOGS_DIRECTORY)

info_logger = setup_logger('info_logger', local_config.LOGS_DIRECTORY)
error_logger = setup_logger('error_logger', local_config.LOGS_DIRECTORY, level=logging.ERROR)

def get_all_attendance_from_device(ip, device_id):
    """Fetches attendance logs from the device."""
    zk = ZK(ip)
    conn = None
    attendances = []
    try:
        conn = zk.connect()
        attendances = conn.get_attendance()
    except Exception as e:
        print(f"Error fetching data from device {ip}: {e}")
    finally:
        if conn:
            conn.disconnect()
    return attendances

def send_to_erpnext(employee, timestamp, device_id=None, log_type=None, biometric_data=None):
    """
    Send attendance data to ERPNext.

    Args:
    - employee (str): The employee's ID or field value.
    - timestamp (datetime): The timestamp of the attendance.
    - device_id (str, optional): The device ID. Defaults to None.
    - log_type (str, optional): The log type. Defaults to None.
    - biometric_data (dict, optional): The biometric attendance data. Defaults to None.

    Returns:
    - tuple: A tuple containing the status code and the response message.
    """
    try:
        url = local_config.ERPNEXT_URL + "/api/resource/Employee Checkin"
        headers = {
            'Authorization': "token "+ local_config.ERPNEXT_API_KEY + ":" + local_config.ERPNEXT_API_SECRET,
            'Accept': 'application/json',
            'Content-Type': 'application/json'
        }
        data = {
            "employee": employee,
            "timestamp": timestamp.isoformat()  # Convert datetime to a string
        }
        response = requests.post(url, headers=headers, data=json.dumps(data))
        if response.status_code == 200:
            return 200, response.json().get('message', {}).get('name', 'Unknown Success Response')
        else:
            error_str = _safe_get_error_str(response)
            error_logger.error('\t'.join([
                'Error during ERPNext API Call.',
                str(employee),
                str(timestamp.timestamp()),
                str(device_id),
                str(log_type),
                error_str
            ]))
            return response.status_code, error_str
    except requests.exceptions.HTTPError:
        error_logger.error('HTTP Error occurred')
        return 500, 'HTTP Error'
    except requests.exceptions.ConnectionError:
        error_logger.error('Error connecting to ERPNext API')
        return 500, 'Connection error'
    except requests.exceptions.Timeout:
        error_logger.error('Timeout error')
        return 500, 'Timeout error'
    except requests.exceptions.RequestException:
        error_logger.error('Something went wrong')
        return 500, 'Request exception'

def _safe_get_error_str(response):
    """
    Safely extract error message from the response.

    Args:
    - response (Response): The HTTP response object.

    Returns:
    - str: The error message.
    """
    try:
        return response.json().get('message', 'Unknown Error')
    except Exception as e:
        return str(e)

def check_employee_status(employee):
    """
    Check the status of an employee in ERPNext.

    Args:
    - employee (str): The employee's ID or field value.

    Returns:
    - bool: True if the employee is active, False otherwise.
    """
    try:
        url = local_config.ERPNEXT_URL + "/api/resource/Employee"
        headers = {
            'Authorization': "token "+ local_config.ERPNEXT_API_KEY + ":" + local_config.ERPNEXT_API_SECRET,
            'Accept': 'application/json',
            'Content-Type': 'application/json'
        }
        params = {
            "filters": {
                "employee": employee
            },
            "fields": ["status"]
        }
        response = requests.get(url, headers=headers, params=params)
        if response.status_code == 200:
            data = response.json().get('data', [])
            if data:
                return data[0].get('status') == 'Active'
            else:
                return False
        else:
            error_str = _safe_get_error_str(response)
            error_logger.error('\t'.join([
                'Error during ERPNext API Call.',
                str(employee),
                error_str
            ]))
            return False
    except requests.exceptions.HTTPError:
        error_logger.error('HTTP Error occurred')
        return False
    except requests.exceptions.ConnectionError:
        error_logger.error('Error connecting to ERPNext API')
        return False
    except requests.exceptions.Timeout:
        error_logger.error('Timeout error')
        return False
    except requests.exceptions.RequestException:
        error_logger.error('Something went wrong')
        return False

def export_biometric_data(date):
    """Export biometric data for the given date to a JSON file."""
    output_file = os.path.join(local_config.LOGS_DIRECTORY, f"biometric_data_{date}.json")
    data_to_export = []

    try:
        for device in local_config.devices:
            print(f"Processing device {device['device_id']}...")
            logs = get_all_attendance_from_device(device['ip'], device['device_id'])

            filtered_logs = [
                {
                    'user_id': f"T{int(log.user_id):06d}",
                    'timestamp': log.timestamp.strftime('%d-%m-%Y %H:%M:%S')
                }
                for log in logs if log.timestamp.strftime('%d-%m-%Y') == date
            ]

            data_to_export.extend(filtered_logs)
    except Exception as e:
        print(f"Error exporting data: {e}")
        return

    try:
        with open(output_file, 'w') as f:
            json.dump(data_to_export, f, indent=4)
        print(f"Biometric data successfully exported to {output_file}")
    except Exception as e:
        print(f"Error writing to file: {e}")

    # Push the exported data to ERPNext
    failed_attendance_logs = []
    for log in data_to_export:
        user_id = log['user_id']
        timestamp = datetime.datetime.strptime(log['timestamp'], '%d-%m-%Y %H:%M:%S')
        if check_employee_status(user_id):
            status_code, response_message = send_to_erpnext(user_id, timestamp)
            print(f"Pushing data to ERPNext for user {user_id}...")
            if status_code == 200:
                print(f"Data pushed successfully to ERPNext for user {user_id}: {response_message}")
            else:
                print(f"Failed to push data to ERPNext for user {user_id}: {status_code} - {response_message}")
                failed_attendance_logs.append(log)
        else:
            print(f"Employee {user_id} is not active. Skipping...")
            failed_attendance_logs.append(log)

    # Push failed attendance logs
    if failed_attendance_logs:
        print("Pushing failed attendance logs...")
        for log in failed_attendance_logs:
            user_id = log['user_id']
            timestamp = datetime.datetime.strptime(log['timestamp'], '%d-%m-%Y %H:%M:%S')
            status_code, response_message = send_to_erpnext(user_id, timestamp)
            print(f"Pushing failed attendance log to ERPNext for user {user_id}...")
            if status_code == 200:
                print(f"Failed attendance log pushed successfully to ERPNext for user {user_id}: {response_message}")
            else:
                print(f"Failed to push failed attendance log to ERPNext for user {user_id}: {status_code} - {response_message}")

def cli_menu():
    """Displays the CLI menu and handles user input."""
    print("Welcome to Biometric Integration to Kernel")
    input("Press Enter to continue...")

    while True:
        print("\nPlease select an option:")
        print("1. Get data from Biometric")
        print("2. Exit")

        choice = input("Enter your choice (1/2): ").strip()

        if choice == '1':
            selected_date = input("Enter the date (DD-MM-YYYY): ").strip()
            try:
                datetime.datetime.strptime(selected_date, '%d-%m-%Y')
                export_biometric_data(selected_date)
            except ValueError:
                print("Invalid date format. Please try again.")

        elif choice == '2':
            print("Exiting the program. Goodbye!")
            break

        else:
            print("Invalid choice. Please try again.")

if __name__ == "__main__":
    cli_menu()





-------------------correct format send_to_erpnext-------------
import os
import json
import datetime
import logging
from logging.handlers import RotatingFileHandler
from zk import ZK
import local_config
import requests

def setup_logger(name, log_directory, level=logging.INFO):
    """Set up a JSON logger with a date-based log file name."""
    current_date = datetime.datetime.now().strftime('%d-%m-%Y')
    log_file = os.path.join(local_config.LOGS_DIRECTORY, f"{current_date}_{name}.log")

    formatter = logging.Formatter('%(message)s')
    handler = RotatingFileHandler(log_file, maxBytes=10000000, backupCount=50)
    handler.setFormatter(formatter)

    logger = logging.getLogger(name)
    logger.setLevel(level)
    if not logger.hasHandlers():
        logger.addHandler(handler)

    return logger

if not os.path.exists(local_config.LOGS_DIRECTORY):
    os.makedirs(local_config.LOGS_DIRECTORY)

info_logger = setup_logger('info_logger', local_config.LOGS_DIRECTORY)
error_logger = setup_logger('error_logger', local_config.LOGS_DIRECTORY, level=logging.ERROR)
attendance_success_logger = setup_logger('attendance_success_logger', local_config.LOGS_DIRECTORY)
attendance_failed_logger = setup_logger('attendance_failed_logger', local_config.LOGS_DIRECTORY)

def get_all_attendance_from_device(ip, device_id):
    """Fetches attendance logs from the device."""
    zk = ZK(ip)
    conn = None
    attendances = []
    try:
        conn = zk.connect()
        attendances = conn.get_attendance()
    except Exception as e:
        print(f"Error fetching data from device {ip}: {e}")
    finally:
        if conn:
            conn.disconnect()
    return attendances

def send_to_erpnext(employee, timestamp, device_id=None, log_type=None, biometric_data=None):
    """
    Send attendance data to ERPNext.

    Args:
    - employee (str): The employee's ID or field value.
    - timestamp (str): The timestamp of the attendance.
    - device_id (str, optional): The device ID. Defaults to None.
    - log_type (str, optional): The log type. Defaults to None.
    - biometric_data (dict, optional): The biometric attendance data. Defaults to None.

    Returns:
    - tuple: A tuple containing the status code and the response message.
    """
    try:
        url = local_config.ERPNEXT_URL + "/api/resource/Employee Checkin"
        headers = {
            'Authorization': "token "+ local_config.ERPNEXT_API_KEY + ":" + local_config.ERPNEXT_API_SECRET,
            'Accept': 'application/json',
            'Content-Type': 'application/json'
        }
        data = {
            "employee": employee,
            "time": timestamp  # Use the string timestamp
        }
        response = requests.post(url, headers=headers, data=json.dumps(data))
        if response.status_code == 200:
            return 200, response.json().get('message', {}).get('name', '200 Success Response')
        else:
            error_str = _safe_get_error_str(response)
            error_logger.error('\t'.join([
                'Error during ERPNext API Call.',
                str(employee),
                str(timestamp),
                str(device_id),
                str(log_type),
                error_str
            ]))
            return response.status_code, error_str
    except requests.exceptions.HTTPError:
        error_logger.error('HTTP Error occurred')
        return 500, 'HTTP Error'
    except requests.exceptions.ConnectionError:
        error_logger.error('Error connecting to ERPNext API')
        return 500, 'Connection error'
    except requests.exceptions.Timeout:
        error_logger.error('Timeout error')
        return 500, 'Timeout error'
    except requests.exceptions.RequestException:
        error_logger.error('Something went wrong')
        return 500, 'Request exception'


def _safe_get_error_str(response):
    """
    Safely extract error message from the response.

    Args:
    - response (Response): The HTTP response object.

    Returns:
    - str: The error message.
    """
    try:
        return response.json().get('message', 'Unknown Error')
    except Exception as e:
        return str(e)

def check_employee_status(employee):
    """
    Check the status of an employee in ERPNext.

    Args:
    - employee (str): The employee's ID or field value.

    Returns:
    - bool: True if the employee is active, False otherwise.
    """
    try:
        url = local_config.ERPNEXT_URL + "/api/resource/Employee"
        headers = {
            'Authorization': "token "+ local_config.ERPNEXT_API_KEY + ":" + local_config.ERPNEXT_API_SECRET,
            'Accept': 'application/json',
            'Content-Type': 'application/json'
        }
        params = {
            "filters": {
                "employee": employee
            },
            "fields": ["status"]
        }
        response = requests.get(url, headers=headers, params=params)
        if response.status_code == 200:
            data = response.json().get('data', [])
            if data:
                return data[0].get('status') == 'Active'
            else:
                return False
        else:
            error_str = _safe_get_error_str(response)
            error_logger.error('\t'.join([
                'Error during ERPNext API Call.',
                str(employee),
                error_str
            ]))
            return False
    except requests.exceptions.HTTPError:
        error_logger.error('HTTP Error occurred')
        return False
    except requests.exceptions.ConnectionError:
        error_logger.error('Error connecting to ERPNext API')
        return False
    except requests.exceptions.Timeout:
        error_logger.error('Timeout error')
        return False
    except requests.exceptions.RequestException:
        error_logger.error('Something went wrong')
        return False

def export_biometric_data(date):
    """Export biometric data for the given date to a JSON file."""
    output_file = os.path.join(local_config.LOGS_DIRECTORY, f"biometric_data_{date}.json")
    data_to_export = []
    not_active_count = 0
    success_count = 0
    failed_count = 0

    try:
        for device in local_config.devices:
            print(f"Processing device {device['device_id']}...")
            logs = get_all_attendance_from_device(device['ip'], device['device_id'])

            filtered_logs = [
                {
                    'user_id': f"T{int(log.user_id):06d}",
                    'timestamp': log.timestamp.strftime('%Y-%m-%d %H:%M:%S')
                }
                for log in logs if log.timestamp.strftime('%Y-%m-%d') == date
            ]

            data_to_export.extend(filtered_logs)
    except Exception as e:
        print(f"Error exporting data: {e}")
        return

    try:
        with open(output_file, 'w') as f:
            json.dump(data_to_export, f, indent=4)
        print(f"Biometric data successfully exported to {output_file}")
    except Exception as e:
        print(f"Error writing to file: {e}")

    # Push the exported data to ERPNext
    failed_attendance_logs = []
    for log in data_to_export:
        user_id = log['user_id']
        timestamp_str = log['timestamp']
        if check_employee_status(user_id):
            status_code, response_message = send_to_erpnext(user_id, timestamp_str)
            print(f"Pushing data to ERPNext for user {user_id}...")
            if status_code == 200:
                print(f"Data pushed successfully to ERPNext for user {user_id}: {response_message}")
                attendance_success_logger.error(f"User {user_id} attendance pushed successfully to ERPNext at {timestamp_str}")
            else:
                print(f"Failed to push data to ERPNext for user {user_id}: {status_code} - {response_message}")
                attendance_failed_logger.error(f"Failed to push attendance data for user {user_id} to ERPNext at {timestamp_str}: {status_code} - {response_message}")
                failed_attendance_logs.append(log)
        else:
            print(f"Employee {user_id} is not active. Skipping...")
            attendance_failed_logger.error(f"Employee {user_id} is not active. Skipping attendance log at {timestamp_str}")
            failed_attendance_logs.append(log)

    # Push failed attendance logs
    if failed_attendance_logs:
        print("Pushing failed attendance logs...")
        for log in failed_attendance_logs:
            user_id = log['user_id']
            timestamp_str = log['timestamp']
            status_code, response_message = send_to_erpnext(user_id, timestamp_str)
            # print(f"Pushing failed attendance log to ERPNext for user {user_id}...")
            if status_code == 200:
                print(f"Attendance log pushed successfully to ERPNext for user {user_id}: {response_message}")
                attendance_success_logger.error(f"Attendance log for user {user_id} pushed successfully to ERPNext at {timestamp_str}")
            else:
                print(f"Failed to push failed attendance log to ERPNext for user {user_id}: {status_code} - {response_message}")
                attendance_failed_logger.error(f"Failed to push failed attendance log to ERPNext for user {user_id} at {timestamp_str}: {status_code} - {response_message}")



def cli_menu():
    """Displays the CLI menu and handles user input."""
    print("Welcome to Biometric Integration to Kernel")
    input("Press Enter to continue...")

    while True:
        print("\nPlease select an option:")
        print("1. Get data from Biometric")
        print("2. Exit")

        choice = input("Enter your choice (1/2): ").strip()

        if choice == '1':
            selected_date = input("Enter the date (DD-MM-YYYY): ").strip()
            try:
                datetime.datetime.strptime(selected_date, '%Y-%m-%d')
                export_biometric_data(selected_date)
            except ValueError:
                print("Invalid date format. Please try again.")

        elif choice == '2':
            print("Exiting the program. Goodbye!")
            break

        else:
            print("Invalid choice. Please try again.")

if __name__ == "__main__":
    cli_menu()



 
